{"cells":[{"cell_type":"markdown","metadata":{"id":"DHC5HT_ihaJH"},"source":["# Importar librerías"]},{"cell_type":"code","source":["!pip install tensorflow==2.15.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDbFINcVowBw","executionInfo":{"status":"ok","timestamp":1732710908151,"user_tz":180,"elapsed":62331,"user":{"displayName":"Lucia Masciangelo","userId":"02380895951670821345"}},"outputId":"6f274a24-28b7-4298-a308-f2ddbf411de0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.15.1\n","  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.12.2)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n","  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.68.0)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n","Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.16.0\n","    Uninstalling wrapt-1.16.0:\n","      Successfully uninstalled wrapt-1.16.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.5.0\n","    Uninstalling keras-3.5.0:\n","      Successfully uninstalled keras-3.5.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.1\n","    Uninstalling tensorboard-2.17.1:\n","      Successfully uninstalled tensorboard-2.17.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n","      Successfully uninstalled tensorflow-2.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BkG_oDGhaJI"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"markdown","metadata":{"id":"Sbsc-G4khaJJ"},"source":["# Descargar y leer el dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lb2vHCXqhaJJ","executionInfo":{"status":"ok","timestamp":1732710913080,"user_tz":180,"elapsed":43,"user":{"displayName":"Lucia Masciangelo","userId":"02380895951670821345"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"564055e7-1d74-4a54-abe5-e6db56ba2cb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}],"source":["dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n","path_to_file = tf.keras.utils.get_file(\"shakespeare.txt\", dataset_url)"]},{"cell_type":"markdown","metadata":{"id":"3pVRTujHhaJJ"},"source":["# Leer y explorar el texto"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKUEnYYhhaJK","executionInfo":{"status":"ok","timestamp":1732710913081,"user_tz":180,"elapsed":24,"user":{"displayName":"Lucia Masciangelo","userId":"02380895951670821345"}},"outputId":"b993dc20-0a4b-4286-b864-f82de6e3768f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 1115394 characters\n","First 500 characters:\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor\n"]}],"source":["text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","print(f'Length of text: {len(text)} characters')\n","#imprimimos los primeros 500 caracteres del texto:\n","print(f'First 500 characters:\\n{text[:500]}')"]},{"cell_type":"markdown","metadata":{"id":"uZ9ycBCLhaJK"},"source":["# Modelo carácter a carácter"]},{"cell_type":"markdown","metadata":{"id":"pEiWxFlThaJK"},"source":["## 1. Preprocesamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbZON94shaJL","executionInfo":{"status":"ok","timestamp":1732657071442,"user_tz":180,"elapsed":6,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"28a2a279-a184-4e51-a9e7-6fb558fa5000"},"outputs":[{"output_type":"stream","name":"stdout","text":["65 unique characters\n"]}],"source":["#Se extraen los carácteres únicos del texto con el objetivo de construir el vocabulario.\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJDDuluRhaJL","executionInfo":{"status":"ok","timestamp":1732657071703,"user_tz":180,"elapsed":266,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"e9d7cf10-af39-4510-e81e-2db11da34e3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=string, numpy=array([b'F', b'i', b'r', ..., b'g', b'.', b'\\n'], dtype=object)>"]},"metadata":{},"execution_count":54}],"source":["chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\n","chars"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rtx3xsv2haJL"},"outputs":[],"source":["ids_from_chars = tf.keras.layers.StringLookup(\n","    vocabulary=list(vocab), mask_token=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbZpbvV6haJL","executionInfo":{"status":"ok","timestamp":1732657072562,"user_tz":180,"elapsed":862,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"d6559359-b1cd-4509-ed07-df24fcfa71c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"metadata":{},"execution_count":56}],"source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JReyNEe4haJM","executionInfo":{"status":"ok","timestamp":1732657072562,"user_tz":180,"elapsed":7,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"ad887813-a9bd-44e7-da2a-644411d65b26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"metadata":{},"execution_count":57}],"source":["ids = ids_from_chars(chars)\n","ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XripezSNhaJM"},"outputs":[],"source":["chars_from_ids = tf.keras.layers.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FA4eusdWhaJM","executionInfo":{"status":"ok","timestamp":1732657072562,"user_tz":180,"elapsed":6,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"91222380-08ac-41b2-e5bb-b64d11259db0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=string, numpy=array([b'F', b'i', b'r', ..., b'g', b'.', b'\\n'], dtype=object)>"]},"metadata":{},"execution_count":59}],"source":["chars = chars_from_ids(ids)\n","chars"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1nuGdalhaJM"},"outputs":[],"source":["#convertimos los índices a texto\n","def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"d0_eLrcLhaJM"},"source":["## Convertir texto en IDs y generar secuencias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cEIJkxshaJN","executionInfo":{"status":"ok","timestamp":1732657073682,"user_tz":180,"elapsed":1125,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"c2bb41d6-1c5b-4152-fd9a-8a4d715952d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"metadata":{},"execution_count":61}],"source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0EZ_vuDhaJN"},"outputs":[],"source":["#Dataset en base a los índices númericos del texto\n","ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wxqy4e6GhaJN","executionInfo":{"status":"ok","timestamp":1732657073683,"user_tz":180,"elapsed":12,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"901ca944-b451-4d81-e162-ed22466f31c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}],"source":["#primeros 10 índices convertidos a caracteres\n","for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mExM3a86haJN"},"outputs":[],"source":["seq_length = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCWATW_qhaJN","executionInfo":{"status":"ok","timestamp":1732657073683,"user_tz":180,"elapsed":12,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"2605cc6f-84d6-44a8-eaa1-26c09a4f35f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n"," b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n"," b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n"," b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n"," b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n"," b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n"," b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n"," b'o' b'u' b' '], shape=(101,), dtype=string)\n"]}],"source":["#establecemos secuencias de longitud fija\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DoRci0eDhaJN","executionInfo":{"status":"ok","timestamp":1732657073683,"user_tz":180,"elapsed":10,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"0d229b72-9bfb-4e77-8d99-fb1873e79efc"},"outputs":[{"output_type":"stream","name":"stdout","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}],"source":["for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iyjb7aA9haJN"},"outputs":[],"source":["#secuencia en dos partes;\n","#entrada: secuencia sin el último carácter, y objetivo: secuencia sin el primer carácter.\n","def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wDbBfXAhaJO","executionInfo":{"status":"ok","timestamp":1732657073683,"user_tz":180,"elapsed":9,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"23e9e843-5ecd-41e8-c34f-4dd50c755524"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['J',\n","  'u',\n","  'l',\n","  'i',\n","  'á',\n","  'n',\n","  ' ',\n","  'e',\n","  's',\n","  ' ',\n","  'u',\n","  'n',\n","  ' ',\n","  'c',\n","  'a',\n","  'p'],\n"," ['u',\n","  'l',\n","  'i',\n","  'á',\n","  'n',\n","  ' ',\n","  'e',\n","  's',\n","  ' ',\n","  'u',\n","  'n',\n","  ' ',\n","  'c',\n","  'a',\n","  'p',\n","  'o'])"]},"metadata":{},"execution_count":68}],"source":[";split_input_target(list(\"Julián es un capo\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ovmIhMdhaJO"},"outputs":[],"source":["dataset = sequences.map(split_input_target)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-7ZBDn_haJO","executionInfo":{"status":"ok","timestamp":1732657074139,"user_tz":180,"elapsed":7,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"b8d1365d-48d1-4669-af24-0330ad4defea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}],"source":["for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"]},{"cell_type":"markdown","metadata":{"id":"qMhfyCS-haJO"},"source":["## 2. Construcción del modelo"]},{"cell_type":"markdown","source":["Se va a contruir, entrenar y utilizar un modelo de red neuronal recurrente (RNN) para predecir texto de forma secuencial dónde se predice el siguiente carácter dado un conjunto de caracteres previos."],"metadata":{"id":"iR9BZs7unQZe"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjiHrCARhaJO","executionInfo":{"status":"ok","timestamp":1732657074139,"user_tz":180,"elapsed":6,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"a0db0ec8-2426-42ea-dc61-551f05347bc4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":71}],"source":["# Batch size\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAEAsYwMhaJO"},"outputs":[],"source":["# Longitud del vocabulario en la capa StringLookup\n","vocab_size = len(ids_from_chars.get_vocabulary())\n","\n","# Dimensión del embedding\n","embedding_dim = 256\n","\n","# Número de unidades RNN\n","rnn_units = 1024"]},{"cell_type":"markdown","source":["Modelo de red neuronal"],"metadata":{"id":"tGh-VZ2ytFbS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXWdTSf6haJO"},"outputs":[],"source":["\n","class MyModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, rnn_units):\n","        super().__init__()\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = tf.keras.layers.GRU(\n","            rnn_units,\n","            return_sequences=True,\n","            return_state=True\n","        )\n","        self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, inputs, states=None, return_state=False, training=False):\n","      x = self.embedding(inputs)\n","      if states is None:\n","        states = self.gru.get_initial_state(x)\n","      x, states = self.gru(x, initial_state=states, training=training)\n","      x = self.dense(x, training=training)\n","\n","      if return_state:\n","        return x, states\n","      else:\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOy4rfQNhaJO"},"outputs":[],"source":["model = MyModel(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_OhD-E3ZhaJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084424,"user_tz":180,"elapsed":10289,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"3684b629-1ce0-49f6-ac3e-da0a447b4e98"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ngn5UwMwhaJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084424,"user_tz":180,"elapsed":15,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"7dd9e086-5433-4697-c0a3-12c686baf87a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     multiple                  16896     \n","                                                                 \n"," gru_2 (GRU)                 multiple                  3938304   \n","                                                                 \n"," dense_2 (Dense)             multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4022850 (15.35 MB)\n","Trainable params: 4022850 (15.35 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEL5TiTRhaJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084425,"user_tz":180,"elapsed":13,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"371f4784-c1af-4460-d0bb-0f918929852f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([36, 13, 61, 45, 57, 25, 47, 64, 35, 47, 65, 57, 41, 45, 29, 20, 58,\n","        1, 19, 31, 23, 43, 61, 64, 61, 43, 46,  4, 36, 24, 11, 36, 44, 43,\n","       41, 51, 27, 34, 31, 60, 48, 62, 48, 35, 41, 62, 25, 41, 39, 44, 26,\n","       65, 56, 47, 56, 59, 25, 52, 59,  6, 63, 28, 10, 53, 64, 17, 34, 36,\n","        6, 61, 10, 16, 46, 41, 59, 44, 49, 36, 33, 18, 36, 25, 32,  4, 57,\n","        4, 29, 31, 12, 16, 56, 26, 15, 32, 28, 36,  8, 51, 55, 52])"]},"metadata":{},"execution_count":77}],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","sampled_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1SGGRTZhaJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084425,"user_tz":180,"elapsed":12,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"008a87d6-38f3-43e0-d76f-41a46f21cfb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n"," b'KE:\\nThy pains, Fitzwater, shall not be forgot;\\nRight noble is thy merit, well I wot.\\n\\nHENRY PERCY:\\nT'\n","\n","Next Char Predictions:\n"," b\"W?vfrLhyVhzrbfPGs\\nFRJdvyvdg$WK:WedblNURuiwiVbwLbZeMzqhqtLmt'xO3nyDUW'v3CgbtejWTEWLS$r$PR;CqMBSOW-lpm\"\n"]}],"source":["print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2eyYiBAhaJP"},"outputs":[],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_mS5pK-yhaJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084425,"user_tz":180,"elapsed":10,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"346dca32-8372-4e8d-8c6b-45dd4b394551"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.1909533, shape=(), dtype=float32)\n"]}],"source":["example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", example_batch_mean_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK7CXJYWhaJT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657084425,"user_tz":180,"elapsed":9,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"7e313c95-3d12-4021-9086-eaba427e66c9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["66.085754"]},"metadata":{},"execution_count":81}],"source":["tf.exp(example_batch_mean_loss).numpy()"]},{"cell_type":"markdown","source":["Entrenamiento del modelo"],"metadata":{"id":"jTs5TGTos61F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_u-tXnshaJT"},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQaJLTAHhaJT"},"outputs":[],"source":["# Directorio donde guardo los checkpoint\n","checkpoint_dir = './training_checkpoints'\n","os.makedirs(checkpoint_dir, exist_ok=True)  # Crea el directorio si no existe\n","\n","#Nombre de los archivos de checkpoint\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","#guardo los pesos del modelo\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=False\n",")\n","\n","#para evitar overfitting\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='loss',          # O 'val_loss' si tienes validación\n","    patience=5,              # Número de épocas sin mejora antes de detener\n","    restore_best_weights=True # Restaura los pesos del mejor modelo\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8whg9nV3haJT"},"outputs":[],"source":["EPOCHS = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7Fc7iCihaJT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732657927265,"user_tz":180,"elapsed":821084,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"91ad17b1-813b-4724-defb-fa723cd5bab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","172/172 [==============================] - 15s 71ms/step - loss: 2.7278\n","Epoch 2/100\n","172/172 [==============================] - 14s 72ms/step - loss: 1.9942\n","Epoch 3/100\n","172/172 [==============================] - 14s 72ms/step - loss: 1.7194\n","Epoch 4/100\n","172/172 [==============================] - 14s 73ms/step - loss: 1.5583\n","Epoch 5/100\n","172/172 [==============================] - 15s 75ms/step - loss: 1.4589\n","Epoch 6/100\n","172/172 [==============================] - 18s 74ms/step - loss: 1.3904\n","Epoch 7/100\n","172/172 [==============================] - 14s 72ms/step - loss: 1.3376\n","Epoch 8/100\n","172/172 [==============================] - 15s 74ms/step - loss: 1.2929\n","Epoch 9/100\n","172/172 [==============================] - 15s 80ms/step - loss: 1.2529\n","Epoch 10/100\n","172/172 [==============================] - 14s 73ms/step - loss: 1.2121\n","Epoch 11/100\n","172/172 [==============================] - 15s 81ms/step - loss: 1.1737\n","Epoch 12/100\n","172/172 [==============================] - 16s 75ms/step - loss: 1.1342\n","Epoch 13/100\n","172/172 [==============================] - 14s 73ms/step - loss: 1.0920\n","Epoch 14/100\n","172/172 [==============================] - 14s 74ms/step - loss: 1.0477\n","Epoch 15/100\n","172/172 [==============================] - 14s 71ms/step - loss: 1.0002\n","Epoch 16/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.9502\n","Epoch 17/100\n","172/172 [==============================] - 14s 73ms/step - loss: 0.8993\n","Epoch 18/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.8468\n","Epoch 19/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.7950\n","Epoch 20/100\n","172/172 [==============================] - 15s 73ms/step - loss: 0.7456\n","Epoch 21/100\n","172/172 [==============================] - 14s 73ms/step - loss: 0.6995\n","Epoch 22/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.6572\n","Epoch 23/100\n","172/172 [==============================] - 16s 75ms/step - loss: 0.6212\n","Epoch 24/100\n","172/172 [==============================] - 14s 74ms/step - loss: 0.5891\n","Epoch 25/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.5620\n","Epoch 26/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.5373\n","Epoch 27/100\n","172/172 [==============================] - 15s 75ms/step - loss: 0.5201\n","Epoch 28/100\n","172/172 [==============================] - 14s 70ms/step - loss: 0.5018\n","Epoch 29/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4892\n","Epoch 30/100\n","172/172 [==============================] - 15s 76ms/step - loss: 0.4777\n","Epoch 31/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4670\n","Epoch 32/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.4579\n","Epoch 33/100\n","172/172 [==============================] - 15s 76ms/step - loss: 0.4532\n","Epoch 34/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4500\n","Epoch 35/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4447\n","Epoch 36/100\n","172/172 [==============================] - 14s 73ms/step - loss: 0.4403\n","Epoch 37/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4322\n","Epoch 38/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4286\n","Epoch 39/100\n","172/172 [==============================] - 15s 76ms/step - loss: 0.4275\n","Epoch 40/100\n","172/172 [==============================] - 15s 75ms/step - loss: 0.4214\n","Epoch 41/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.4197\n","Epoch 42/100\n","172/172 [==============================] - 14s 74ms/step - loss: 0.4179\n","Epoch 43/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4235\n","Epoch 44/100\n","172/172 [==============================] - 14s 73ms/step - loss: 0.4193\n","Epoch 45/100\n","172/172 [==============================] - 14s 75ms/step - loss: 0.4176\n","Epoch 46/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.4192\n","Epoch 47/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4192\n","Epoch 48/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4202\n","Epoch 49/100\n","172/172 [==============================] - 14s 74ms/step - loss: 0.4156\n","Epoch 50/100\n","172/172 [==============================] - 17s 87ms/step - loss: 0.4184\n","Epoch 51/100\n","172/172 [==============================] - 16s 75ms/step - loss: 0.4262\n","Epoch 52/100\n","172/172 [==============================] - 16s 83ms/step - loss: 0.4256\n","Epoch 53/100\n","172/172 [==============================] - 14s 71ms/step - loss: 0.4248\n","Epoch 54/100\n","172/172 [==============================] - 14s 72ms/step - loss: 0.4243\n"]}],"source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, early_stopping])"]},{"cell_type":"markdown","source":["Genero texto con temperatura"],"metadata":{"id":"58FuC0NWsVzk"}},{"cell_type":"code","source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","\n","#se genera un carácter\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"],"metadata":{"id":"tkeTewCC_FeZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_step_model_02 = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.2)\n","one_step_model_05 = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.5)\n","one_step_model_07 = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.7)\n","one_step_model_10 = OneStep(model, chars_from_ids, ids_from_chars)\n","one_step_model_15 = OneStep(model, chars_from_ids, ids_from_chars, temperature=1.5)\n","one_step_model_30 = OneStep(model, chars_from_ids, ids_from_chars, temperature=3)"],"metadata":{"id":"OfI5eGJz_Hun"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- temp 0.2"],"metadata":{"id":"22wwjwyZAqja"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_02.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjjhx6TF_Jm6","executionInfo":{"status":"ok","timestamp":1732657937472,"user_tz":180,"elapsed":3779,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"c8e23586-0535-4050-c2d0-6636dcb729f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Ye'rayed his enemies,\n","Recove his broken stronger by him.\n","Farewell, sweet whensway: believe me, and speak not straight,\n","Where the northern lames are up, I treach you so it,\n","It is no sentinuse makes yourself.\n","\n","CORIOLANUS:\n","Have you voices?\n","\n","FRAAN:\n","God save your loyal sigh!--\n","Do, good my lord, and leave us here,\n","And make my wars on my true and like a father's death,\n","And not by love, and I'll be her birth.\n","\n","KING RICHARD II:\n","The charge I bore half my desire yet instruction\n","may sigh and still appear go to your grace,\n","The latest not speak with men allow,\n","I never indeed had send the adventure\n","Where nothing can be in readiness.\n","\n","NORSOLIO:\n","What is the matter?\n","\n","DUKE OF YORK:\n","Perishon, madam: there's some coats blush'd unto their news.\n","\n","GRUMIO:\n","Ay, marroast; and, as I said, and a half,\n","Or if you lie done words; I see Queen Margaret, as the way before.\n","\n","KING RICHARD II:\n","We will ourselves whilst you have charged a king of\n","breath; there is some wandering that the duty where\n","The end of such a deep wil \n","\n","________________________________________________________________________________\n","\n","Run time: 3.751807451248169\n"]}]},{"cell_type":"markdown","source":["- temp 0.5"],"metadata":{"id":"Gm4AZ0qQAxAw"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_05.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gz-mQjwAuct","executionInfo":{"status":"ok","timestamp":1732657941055,"user_tz":180,"elapsed":3591,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"00e36258-2b4a-4dba-f21c-320ff1945213"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Ye're lords;\n","But let him swear at your suit of farches blood!\n","My prayers are my dreams; who would pluck him\n","to pieces. 'Parcest Master Froth: fame, it is Aufidius,\n","When this is were distinuted: he said he would\n","May stand alive; and then to give them would\n","Condition of streaks, and come with thee my fleet,\n","To make a meeting through the sacrament,\n","To strive to blazed, or wrongfully and usurps\n","always grant to sund. My track men faith,\n","I'll tell you now, see that attain it.\n","\n","DUCHESS OF YORK:\n","Art thou my sail! that I have no cause\n","I may breeve not of the dire; and as he says,\n","She shall be married to noon out of their arms.\n","\n","DUKE OF AUMERLE:\n","I brought high Hereford, hate thy crown.\n","\n","WINCENCIOLINA:\n","What must be, whom I do set it on?\n","As son and was a madm that hath the right!\n","Call it a truth words.\n","\n","EXTON:\n","'Halk'st of Burgundy, welcome!\n","\n","AUFIDIUS:\n","I will practed him of perporation:\n","A boy make me browled it; and what thou hast not speak too line\n","That have been absence of them but this?\n","\n","JULIET \n","\n","________________________________________________________________________________\n","\n","Run time: 3.5504844188690186\n"]}]},{"cell_type":"markdown","source":["- temp 0.7"],"metadata":{"id":"rh8oj6hZA4_i"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_07.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyqgPwoQBCj-","executionInfo":{"status":"ok","timestamp":1732657944186,"user_tz":180,"elapsed":3139,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"60ac38d2-64e5-42d4-c75e-06566d9f2af3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Ye'ry to Signifry!\n","\n","CAPULET:\n","What not, that's sweat? Neven where have I done with her.\n","Put thy lady bones, to do your metely,\n","The ceremonious night I am so break, to pity,\n","He'll frown of wall: I end so must thy came yourself\n","Have almost stoly hated.\n","\n","GLOUCESTER:\n","Harp! how my deeds did shall be to soon compassion;\n","All men of England whereal my daughter come;\n","Whilst thou looks are angels like deeds deserving\n","To bear a passing course to bear us.\n","\n","HERMIONE:\n","Should a villain say so,\n","The conquest of you the causes of four-scope:\n","Which once they are coming to you that I parted\n","Bit him here affect his wife and marry his mercy.\n","\n","QUEEN ELIZABETH:\n","My heart is great deplain? All this in them,\n","And thou, Lord Oxford, would the western flight,\n","Appoints my conscience and to help you, if\n","I may not be tedious; and my promise\n","known with counters and my name in love;\n","The fruit-crown fled of restrice, which are here by my charity.\n","\n","QUEEN ELIZABETH:\n","To fearful not set upon a noble demand.\n","Had he none else? \n","\n","________________________________________________________________________________\n","\n","Run time: 3.1019229888916016\n"]}]},{"cell_type":"markdown","source":["- temp 1"],"metadata":{"id":"MOc-_NfEA_Nk"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_10.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDLdcYxfBEZS","executionInfo":{"status":"ok","timestamp":1732657947269,"user_tz":180,"elapsed":3093,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"c4d3ed18-e08b-4564-867c-215e1cdbbe09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Ye'ry we'll haste you. You pity he\n","to death, a dozard to command\n","And do we bound you where her early days:\n","The bloody day is not for our falsehood to thyself\n","And already his countenances, gives it at\n","Your own.\n","\n","ALONSO:\n","Is it is; yet then rejuies that less vower like a league thine well?\n","She meet, my lord, I'll pract myself\n","To trust to make a monarch'd with to slow,\n","To speak by with me; get thee unease,\n","Too power the match if they do not let me speak.\n","\n","WARWICK:\n","I must be content to swear: it not beloved\n","What I saw sund. O, that she did low well believe\n","Henceforth Citizens:\n","An easy task it; and it was by ta'en for\n","His majesty.\n","\n","First Senator:\n","My general-case,\n","My househ heart-so incorplated,\n","Or modest lovers' penuly vow'd up:\n","That reason thus shall stand at Pomfret. Lords, well\n","The valiant and opposeth tears:\n","This dead and honesty to answer them,\n","And from the neck of them shall pay for the least.\n","\n","CLARENCE:\n","\n","Ghost of, Nayler, my lords, kill me?\n","I have heard so much aloud out in hall,\n","And \n","\n","________________________________________________________________________________\n","\n","Run time: 3.0944674015045166\n"]}]},{"cell_type":"markdown","source":["temp 1.5"],"metadata":{"id":"eijAvL8fBBBm"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_15.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGizLktFBF1U","executionInfo":{"status":"ok","timestamp":1732657951091,"user_tz":180,"elapsed":3824,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"056f2495-c335-4083-8ec4-580da8b6a0b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","He hath deserved clothes Plaimns with mine.'\n","\n","AUFIDIUS:\n","God keep yourselves as speact sound\n","And feech the lip of such valour, let us murderous.\n","\n","TRANIO:\n","A vengeance merry; let them respect.\n","\n","TYBALT:\n","Falled them!\n","\n","LADY GREY:\n","Why, then all served in any house;\n","Besides, and thenkering him and show'd;\n","an it hath twenty chaffing vow Juliet's death; no babled sons,\n","Being tenderly Heam Towards cale:\n","If this be nelectly.\n","\n","DUKE VINCENTIO:\n","List. Go, cost I have had ere thee talk'd withal!\n","\n","CATESBY:\n","Ay, my good lord; there is an air of mide\n","Than Edward freely. Go, safe; tempt bityers to secure and well,\n","Let me set not four difficer Kate to you\n","to put breath their guiltly newses, coming won;\n","The bast oranges right acted: alth, that\n","Apollo plucked that up will fought;\n","Awakes, nay, nay, my doom and London,\n","To see her bewartire heads but wave thy way;\n","Yick-brid came then my deserves at spates for Rome;\n","The banner so through at all to late,\n","To bear a park appray, and thereby the eastern comes to blam \n","\n","________________________________________________________________________________\n","\n","Run time: 3.8468551635742188\n"]}]},{"cell_type":"markdown","source":["- temp 3"],"metadata":{"id":"xEAWuZnZZh68"}},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant(['First Citizen:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model_30.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJionMFcZhkc","executionInfo":{"status":"ok","timestamp":1732657954195,"user_tz":180,"elapsed":3108,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"0290b796-4ac7-43af-a050-aa5b1b75a1cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","He call'd me-loy,' slaughter'd resign,\n","Wroth, my sona, Wilker Earlt the powe, call-Piked.\n","So, underingrancely numbers were,\n","I would starely in the best from slue inJEnque for vein,\n","Constant thea!\n","\n","Gaoutor:\n","Obey,\n","and melrown, this it his, Pemery and Lord!\n","Heveok-wife, Hencoin sta't; I knywife.\n","Now, obisably.\n","\n","VolsaX\n","ADO:\n","Howal; t! andZGurst i' the Couctim-'s nobor?' daig, wied's paper?\n","Ah, Rarely's king!' Wef-dain!\n","Cede? hope, limis,ed Balk against their Gues:\n","ehe I that jest drybesh frammingbyiefds; igh the warcupal Wreth!\n","Ah, Wyry,t by urthwazen through us, bown, deserves,\n","Shalt Laybas TaPqoivis cups vigoward up; unchapquity,\n","Amb Puby's wit; my po! inhesiage and honority.\n","It is's, Poliant's awnqu: if CprostERBus!\n","Bring for, thought! and, FrameL, deadly Kate!\n","Did loudh'd yet again; a you!\n","Brag means\n","So, vio! Nay, besurry, to-morrow makest!\n","Give sort gots what I rove, hut, Boausen king!\n","Keep, wholesome-hearted friend no limit?\n","Wa wigodorts, bowsil'st you, Lucio!\n","Leaven lueges my tender \n","\n","________________________________________________________________________________\n","\n","Run time: 3.0783815383911133\n"]}]},{"cell_type":"markdown","source":["Guardo los pesos del entrenamiento"],"metadata":{"id":"tyf0xAIPsMqI"}},{"cell_type":"code","source":["\n","folder_name = \"/content/training_checkpoints/ckpt_54\"\n","zip_name = \"training_checkpoin.zip\"\n","\n","# Comprime la carpeta\n","!zip -r {zip_name} {folder_name}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSSt8Dq0BvyO","executionInfo":{"status":"ok","timestamp":1732658081986,"user_tz":180,"elapsed":2892,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"38685053-9dc0-497d-d8e7-fd16f5873dc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/training_checkpoints/ckpt_54/ (stored 0%)\n","  adding: content/training_checkpoints/ckpt_54/saved_model.pb (deflated 89%)\n","  adding: content/training_checkpoints/ckpt_54/keras_metadata.pb (deflated 78%)\n","  adding: content/training_checkpoints/ckpt_54/variables/ (stored 0%)\n","  adding: content/training_checkpoints/ckpt_54/variables/variables.data-00000-of-00001 (deflated 8%)\n","  adding: content/training_checkpoints/ckpt_54/variables/variables.index (deflated 59%)\n","  adding: content/training_checkpoints/ckpt_54/assets/ (stored 0%)\n","  adding: content/training_checkpoints/ckpt_54/fingerprint.pb (stored 0%)\n"]}]},{"cell_type":"markdown","source":["https://colab.research.google.com/github/FCEIA-AAII/lab10/blob/master/lab10-a.ipynb#scrollTo=ST7PSyk9t1mT"],"metadata":{"id":"BIbcI9EOCsip"}},{"cell_type":"markdown","source":["A pesar de tener un tiempo de ejecución bastante consistente al generar 1000 carácteres. Podemos observar que a menor temperatura la generación es más coherente y con poca creatividad. Ocurriendo lo contrario a medida que se aumenta la temperatura."],"metadata":{"id":"vSA19ztfrOUn"}},{"cell_type":"markdown","source":["# Palabra"],"metadata":{"id":"olLapLG6XL58"}},{"cell_type":"markdown","source":["## Tokenización basada en palabras"],"metadata":{"id":"JkPHD1TKfGtp"}},{"cell_type":"markdown","source":["Divide el texto en palabras únicas y crea los mapeos entre palabras e IDs.\n","\n"],"metadata":{"id":"s_grGcKDfT71"}},{"cell_type":"code","source":["# Dividir el texto en palabras\n","words = tf.strings.split(text)\n","vocab = sorted(set(words.numpy()))  # Vocabulario único\n","print(f'{len(vocab)} unique words')\n","\n","# Mapear palabras a índices y viceversa\n","words_from_ids = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True, mask_token=None)\n","ids_from_words = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)\n","\n","# Convertir el texto a IDs\n","all_ids = ids_from_words(words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMSe-IwQXpOc","executionInfo":{"status":"ok","timestamp":1732658402038,"user_tz":180,"elapsed":841,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"b298bcef-80c4-4ae5-a29f-a82af3e52413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25670 unique words\n"]}]},{"cell_type":"markdown","source":["## Preparación de datos para entrenamiento"],"metadata":{"id":"V-zq62Y5fWwR"}},{"cell_type":"markdown","source":["Crea secuencias de palabras para entrenar el modelo y divide cada secuencia en entradas y objetivos."],"metadata":{"id":"0s8X_LSSfYXo"}},{"cell_type":"code","source":["# Crear secuencias de palabras\n","seq_length = 50  # Longitud de las secuencias\n","sequences = tf.data.Dataset.from_tensor_slices(all_ids).batch(seq_length + 1, drop_remainder=True)\n","\n","# Dividir secuencias en entrada y objetivo\n","def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)\n","\n","# Configurar dataset para entrenamiento\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE)\n",")\n"],"metadata":{"id":"HBxU2lzWdL-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definición del modelo basado en palabras"],"metadata":{"id":"gPuBAYlHfbRd"}},{"cell_type":"markdown","source":["Crea un modelo con embeddings, una capa GRU y una capa densa para predecir palabras."],"metadata":{"id":"Dv9J-xfcfcmP"}},{"cell_type":"code","source":["# Configuración del modelo\n","vocab_size = len(vocab) + 1  # +1 para el índice 0 reservado\n","embedding_dim = 256\n","rnn_units = 1024\n","\n","class WordModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, rnn_units):\n","        super().__init__()\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = tf.keras.layers.GRU(\n","            rnn_units,\n","            return_sequences=True,\n","            return_state=True\n","        )\n","        self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, inputs, states=None, return_state=False, training=False):\n","        x = self.embedding(inputs)\n","        if states is None:\n","            states = self.gru.get_initial_state(x)\n","        x, states = self.gru(x, initial_state=states, training=training)\n","        x = self.dense(x, training=training)\n","        return (x, states) if return_state else x\n","\n","# Crear instancia del modelo\n","word_based_model = WordModel(vocab_size, embedding_dim, rnn_units)\n"],"metadata":{"id":"Jdxo1QxWfdQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compilación y entrenamiento del modelo"],"metadata":{"id":"AEU7_oX8fqrb"}},{"cell_type":"markdown","source":["Define la función de pérdida y entrena el modelo."],"metadata":{"id":"bgxJTLO8fsaS"}},{"cell_type":"code","source":["# Directorio para guardar checkpoints\n","checkpoint_dir = './word_training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","os.makedirs(checkpoint_dir, exist_ok=True)  # Crear el directorio si no existe\n","\n","# Callback para guardar checkpoints\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=False,  # Solo guarda los pesos\n","    save_best_only=True,     # Guarda solo si es el mejor modelo hasta el momento\n","    monitor='loss',          # Monitorea la pérdida\n","    verbose=1\n",")\n","\n","# Callback para detener el entrenamiento temprano\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n","    monitor='loss',          # Monitorea la pérdida\n","    patience=5,              # Número de épocas sin mejora antes de detener\n","    restore_best_weights=True  # Restaura los pesos del mejor modelo\n",")\n"],"metadata":{"id":"VIXAdUIMf4mi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Función de pérdida\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Compilar el modelo\n","word_based_model.compile(optimizer='adam', loss=loss)\n","\n","# Entrenar el modelo\n","EPOCHS = 100\n"],"metadata":{"id":"Ujd-n1CKfe6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenamiento con callbacks\n","history = word_based_model.fit(\n","    dataset,\n","    epochs=EPOCHS,\n","    callbacks=[checkpoint_callback, early_stopping_callback]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhUATXw-f9oz","executionInfo":{"status":"ok","timestamp":1732660699962,"user_tz":180,"elapsed":1322188,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"00c2dfc4-fdd0-43ca-8318-af5e7088673a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","62/62 [==============================] - ETA: 0s - loss: 6.7383\n","Epoch 1: loss improved from inf to 6.73830, saving model to ./word_training_checkpoints/ckpt_1\n","62/62 [==============================] - 20s 259ms/step - loss: 6.7383\n","Epoch 2/100\n","62/62 [==============================] - ETA: 0s - loss: 6.3323\n","Epoch 2: loss improved from 6.73830 to 6.33229, saving model to ./word_training_checkpoints/ckpt_2\n","62/62 [==============================] - 16s 256ms/step - loss: 6.3323\n","Epoch 3/100\n","62/62 [==============================] - ETA: 0s - loss: 6.0929\n","Epoch 3: loss improved from 6.33229 to 6.09291, saving model to ./word_training_checkpoints/ckpt_3\n","62/62 [==============================] - 16s 246ms/step - loss: 6.0929\n","Epoch 4/100\n","62/62 [==============================] - ETA: 0s - loss: 5.8066\n","Epoch 4: loss improved from 6.09291 to 5.80655, saving model to ./word_training_checkpoints/ckpt_4\n","62/62 [==============================] - 16s 243ms/step - loss: 5.8066\n","Epoch 5/100\n","62/62 [==============================] - ETA: 0s - loss: 5.4623\n","Epoch 5: loss improved from 5.80655 to 5.46233, saving model to ./word_training_checkpoints/ckpt_5\n","62/62 [==============================] - 16s 256ms/step - loss: 5.4623\n","Epoch 6/100\n","62/62 [==============================] - ETA: 0s - loss: 5.0639\n","Epoch 6: loss improved from 5.46233 to 5.06392, saving model to ./word_training_checkpoints/ckpt_6\n","62/62 [==============================] - 19s 298ms/step - loss: 5.0639\n","Epoch 7/100\n","62/62 [==============================] - ETA: 0s - loss: 4.6431\n","Epoch 7: loss improved from 5.06392 to 4.64307, saving model to ./word_training_checkpoints/ckpt_7\n","62/62 [==============================] - 16s 245ms/step - loss: 4.6431\n","Epoch 8/100\n","62/62 [==============================] - ETA: 0s - loss: 4.2290\n","Epoch 8: loss improved from 4.64307 to 4.22904, saving model to ./word_training_checkpoints/ckpt_8\n","62/62 [==============================] - 16s 244ms/step - loss: 4.2290\n","Epoch 9/100\n","62/62 [==============================] - ETA: 0s - loss: 3.8534\n","Epoch 9: loss improved from 4.22904 to 3.85338, saving model to ./word_training_checkpoints/ckpt_9\n","62/62 [==============================] - 18s 290ms/step - loss: 3.8534\n","Epoch 10/100\n","62/62 [==============================] - ETA: 0s - loss: 3.5289\n","Epoch 10: loss improved from 3.85338 to 3.52893, saving model to ./word_training_checkpoints/ckpt_10\n","62/62 [==============================] - 16s 246ms/step - loss: 3.5289\n","Epoch 11/100\n","62/62 [==============================] - ETA: 0s - loss: 3.2373\n","Epoch 11: loss improved from 3.52893 to 3.23725, saving model to ./word_training_checkpoints/ckpt_11\n","62/62 [==============================] - 16s 245ms/step - loss: 3.2373\n","Epoch 12/100\n","62/62 [==============================] - ETA: 0s - loss: 2.9753\n","Epoch 12: loss improved from 3.23725 to 2.97532, saving model to ./word_training_checkpoints/ckpt_12\n","62/62 [==============================] - 17s 268ms/step - loss: 2.9753\n","Epoch 13/100\n","62/62 [==============================] - ETA: 0s - loss: 2.7390\n","Epoch 13: loss improved from 2.97532 to 2.73896, saving model to ./word_training_checkpoints/ckpt_13\n","62/62 [==============================] - 16s 246ms/step - loss: 2.7390\n","Epoch 14/100\n","62/62 [==============================] - ETA: 0s - loss: 2.5231\n","Epoch 14: loss improved from 2.73896 to 2.52313, saving model to ./word_training_checkpoints/ckpt_14\n","62/62 [==============================] - 21s 319ms/step - loss: 2.5231\n","Epoch 15/100\n","62/62 [==============================] - ETA: 0s - loss: 2.3243\n","Epoch 15: loss improved from 2.52313 to 2.32434, saving model to ./word_training_checkpoints/ckpt_15\n","62/62 [==============================] - 16s 248ms/step - loss: 2.3243\n","Epoch 16/100\n","62/62 [==============================] - ETA: 0s - loss: 2.1394\n","Epoch 16: loss improved from 2.32434 to 2.13943, saving model to ./word_training_checkpoints/ckpt_16\n","62/62 [==============================] - 17s 267ms/step - loss: 2.1394\n","Epoch 17/100\n","62/62 [==============================] - ETA: 0s - loss: 1.9699\n","Epoch 17: loss improved from 2.13943 to 1.96987, saving model to ./word_training_checkpoints/ckpt_17\n","62/62 [==============================] - 16s 245ms/step - loss: 1.9699\n","Epoch 18/100\n","62/62 [==============================] - ETA: 0s - loss: 1.8145\n","Epoch 18: loss improved from 1.96987 to 1.81449, saving model to ./word_training_checkpoints/ckpt_18\n","62/62 [==============================] - 17s 276ms/step - loss: 1.8145\n","Epoch 19/100\n","62/62 [==============================] - ETA: 0s - loss: 1.6704\n","Epoch 19: loss improved from 1.81449 to 1.67037, saving model to ./word_training_checkpoints/ckpt_19\n","62/62 [==============================] - 16s 256ms/step - loss: 1.6704\n","Epoch 20/100\n","62/62 [==============================] - ETA: 0s - loss: 1.5363\n","Epoch 20: loss improved from 1.67037 to 1.53631, saving model to ./word_training_checkpoints/ckpt_20\n","62/62 [==============================] - 16s 249ms/step - loss: 1.5363\n","Epoch 21/100\n","62/62 [==============================] - ETA: 0s - loss: 1.4116\n","Epoch 21: loss improved from 1.53631 to 1.41155, saving model to ./word_training_checkpoints/ckpt_21\n","62/62 [==============================] - 16s 245ms/step - loss: 1.4116\n","Epoch 22/100\n","62/62 [==============================] - ETA: 0s - loss: 1.2959\n","Epoch 22: loss improved from 1.41155 to 1.29592, saving model to ./word_training_checkpoints/ckpt_22\n","62/62 [==============================] - 22s 344ms/step - loss: 1.2959\n","Epoch 23/100\n","62/62 [==============================] - ETA: 0s - loss: 1.1900\n","Epoch 23: loss improved from 1.29592 to 1.19001, saving model to ./word_training_checkpoints/ckpt_23\n","62/62 [==============================] - 39s 629ms/step - loss: 1.1900\n","Epoch 24/100\n","62/62 [==============================] - ETA: 0s - loss: 1.0924\n","Epoch 24: loss improved from 1.19001 to 1.09238, saving model to ./word_training_checkpoints/ckpt_24\n","62/62 [==============================] - 15s 242ms/step - loss: 1.0924\n","Epoch 25/100\n","62/62 [==============================] - ETA: 0s - loss: 1.0009\n","Epoch 25: loss improved from 1.09238 to 1.00088, saving model to ./word_training_checkpoints/ckpt_25\n","62/62 [==============================] - 15s 242ms/step - loss: 1.0009\n","Epoch 26/100\n","62/62 [==============================] - ETA: 0s - loss: 0.9136\n","Epoch 26: loss improved from 1.00088 to 0.91363, saving model to ./word_training_checkpoints/ckpt_26\n","62/62 [==============================] - 21s 338ms/step - loss: 0.9136\n","Epoch 27/100\n","62/62 [==============================] - ETA: 0s - loss: 0.8327\n","Epoch 27: loss improved from 0.91363 to 0.83275, saving model to ./word_training_checkpoints/ckpt_27\n","62/62 [==============================] - 23s 358ms/step - loss: 0.8327\n","Epoch 28/100\n","62/62 [==============================] - ETA: 0s - loss: 0.7617\n","Epoch 28: loss improved from 0.83275 to 0.76170, saving model to ./word_training_checkpoints/ckpt_28\n","62/62 [==============================] - 21s 327ms/step - loss: 0.7617\n","Epoch 29/100\n","62/62 [==============================] - ETA: 0s - loss: 0.6927\n","Epoch 29: loss improved from 0.76170 to 0.69271, saving model to ./word_training_checkpoints/ckpt_29\n","62/62 [==============================] - 15s 243ms/step - loss: 0.6927\n","Epoch 30/100\n","62/62 [==============================] - ETA: 0s - loss: 0.6324\n","Epoch 30: loss improved from 0.69271 to 0.63243, saving model to ./word_training_checkpoints/ckpt_30\n","62/62 [==============================] - 27s 430ms/step - loss: 0.6324\n","Epoch 31/100\n","62/62 [==============================] - ETA: 0s - loss: 0.5750\n","Epoch 31: loss improved from 0.63243 to 0.57496, saving model to ./word_training_checkpoints/ckpt_31\n","62/62 [==============================] - 15s 242ms/step - loss: 0.5750\n","Epoch 32/100\n","62/62 [==============================] - ETA: 0s - loss: 0.5214\n","Epoch 32: loss improved from 0.57496 to 0.52140, saving model to ./word_training_checkpoints/ckpt_32\n","62/62 [==============================] - 20s 319ms/step - loss: 0.5214\n","Epoch 33/100\n","62/62 [==============================] - ETA: 0s - loss: 0.4745\n","Epoch 33: loss improved from 0.52140 to 0.47448, saving model to ./word_training_checkpoints/ckpt_33\n","62/62 [==============================] - 16s 251ms/step - loss: 0.4745\n","Epoch 34/100\n","62/62 [==============================] - ETA: 0s - loss: 0.4313\n","Epoch 34: loss improved from 0.47448 to 0.43129, saving model to ./word_training_checkpoints/ckpt_34\n","62/62 [==============================] - 28s 451ms/step - loss: 0.4313\n","Epoch 35/100\n","62/62 [==============================] - ETA: 0s - loss: 0.3926\n","Epoch 35: loss improved from 0.43129 to 0.39262, saving model to ./word_training_checkpoints/ckpt_35\n","62/62 [==============================] - 23s 352ms/step - loss: 0.3926\n","Epoch 36/100\n","62/62 [==============================] - ETA: 0s - loss: 0.3574\n","Epoch 36: loss improved from 0.39262 to 0.35741, saving model to ./word_training_checkpoints/ckpt_36\n","62/62 [==============================] - 16s 247ms/step - loss: 0.3574\n","Epoch 37/100\n","62/62 [==============================] - ETA: 0s - loss: 0.3254\n","Epoch 37: loss improved from 0.35741 to 0.32541, saving model to ./word_training_checkpoints/ckpt_37\n","62/62 [==============================] - 16s 252ms/step - loss: 0.3254\n","Epoch 38/100\n","62/62 [==============================] - ETA: 0s - loss: 0.2968\n","Epoch 38: loss improved from 0.32541 to 0.29680, saving model to ./word_training_checkpoints/ckpt_38\n","62/62 [==============================] - 20s 315ms/step - loss: 0.2968\n","Epoch 39/100\n","62/62 [==============================] - ETA: 0s - loss: 0.2702\n","Epoch 39: loss improved from 0.29680 to 0.27023, saving model to ./word_training_checkpoints/ckpt_39\n","62/62 [==============================] - 15s 243ms/step - loss: 0.2702\n","Epoch 40/100\n","62/62 [==============================] - ETA: 0s - loss: 0.2450\n","Epoch 40: loss improved from 0.27023 to 0.24503, saving model to ./word_training_checkpoints/ckpt_40\n","62/62 [==============================] - 17s 272ms/step - loss: 0.2450\n","Epoch 41/100\n","62/62 [==============================] - ETA: 0s - loss: 0.2242\n","Epoch 41: loss improved from 0.24503 to 0.22422, saving model to ./word_training_checkpoints/ckpt_41\n","62/62 [==============================] - 18s 288ms/step - loss: 0.2242\n","Epoch 42/100\n","62/62 [==============================] - ETA: 0s - loss: 0.2061\n","Epoch 42: loss improved from 0.22422 to 0.20610, saving model to ./word_training_checkpoints/ckpt_42\n","62/62 [==============================] - 25s 393ms/step - loss: 0.2061\n","Epoch 43/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1899\n","Epoch 43: loss improved from 0.20610 to 0.18990, saving model to ./word_training_checkpoints/ckpt_43\n","62/62 [==============================] - 16s 246ms/step - loss: 0.1899\n","Epoch 44/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1748\n","Epoch 44: loss improved from 0.18990 to 0.17477, saving model to ./word_training_checkpoints/ckpt_44\n","62/62 [==============================] - 17s 266ms/step - loss: 0.1748\n","Epoch 45/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1616\n","Epoch 45: loss improved from 0.17477 to 0.16159, saving model to ./word_training_checkpoints/ckpt_45\n","62/62 [==============================] - 19s 305ms/step - loss: 0.1616\n","Epoch 46/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1505\n","Epoch 46: loss improved from 0.16159 to 0.15051, saving model to ./word_training_checkpoints/ckpt_46\n","62/62 [==============================] - 16s 248ms/step - loss: 0.1505\n","Epoch 47/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1410\n","Epoch 47: loss improved from 0.15051 to 0.14101, saving model to ./word_training_checkpoints/ckpt_47\n","62/62 [==============================] - 16s 256ms/step - loss: 0.1410\n","Epoch 48/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1321\n","Epoch 48: loss improved from 0.14101 to 0.13210, saving model to ./word_training_checkpoints/ckpt_48\n","62/62 [==============================] - 16s 255ms/step - loss: 0.1321\n","Epoch 49/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1245\n","Epoch 49: loss improved from 0.13210 to 0.12453, saving model to ./word_training_checkpoints/ckpt_49\n","62/62 [==============================] - 16s 248ms/step - loss: 0.1245\n","Epoch 50/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1183\n","Epoch 50: loss improved from 0.12453 to 0.11827, saving model to ./word_training_checkpoints/ckpt_50\n","62/62 [==============================] - 16s 245ms/step - loss: 0.1183\n","Epoch 51/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1123\n","Epoch 51: loss improved from 0.11827 to 0.11228, saving model to ./word_training_checkpoints/ckpt_51\n","62/62 [==============================] - 16s 246ms/step - loss: 0.1123\n","Epoch 52/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1069\n","Epoch 52: loss improved from 0.11228 to 0.10692, saving model to ./word_training_checkpoints/ckpt_52\n","62/62 [==============================] - 17s 268ms/step - loss: 0.1069\n","Epoch 53/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1027\n","Epoch 53: loss improved from 0.10692 to 0.10272, saving model to ./word_training_checkpoints/ckpt_53\n","62/62 [==============================] - 18s 284ms/step - loss: 0.1027\n","Epoch 54/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0993\n","Epoch 54: loss improved from 0.10272 to 0.09925, saving model to ./word_training_checkpoints/ckpt_54\n","62/62 [==============================] - 16s 251ms/step - loss: 0.0993\n","Epoch 55/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0958\n","Epoch 55: loss improved from 0.09925 to 0.09580, saving model to ./word_training_checkpoints/ckpt_55\n","62/62 [==============================] - 39s 624ms/step - loss: 0.0958\n","Epoch 56/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0924\n","Epoch 56: loss improved from 0.09580 to 0.09244, saving model to ./word_training_checkpoints/ckpt_56\n","62/62 [==============================] - 15s 242ms/step - loss: 0.0924\n","Epoch 57/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0893\n","Epoch 57: loss improved from 0.09244 to 0.08933, saving model to ./word_training_checkpoints/ckpt_57\n","62/62 [==============================] - 17s 272ms/step - loss: 0.0893\n","Epoch 58/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0868\n","Epoch 58: loss improved from 0.08933 to 0.08684, saving model to ./word_training_checkpoints/ckpt_58\n","62/62 [==============================] - 20s 325ms/step - loss: 0.0868\n","Epoch 59/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0845\n","Epoch 59: loss improved from 0.08684 to 0.08451, saving model to ./word_training_checkpoints/ckpt_59\n","62/62 [==============================] - 16s 254ms/step - loss: 0.0845\n","Epoch 60/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0828\n","Epoch 60: loss improved from 0.08451 to 0.08281, saving model to ./word_training_checkpoints/ckpt_60\n","62/62 [==============================] - 15s 241ms/step - loss: 0.0828\n","Epoch 61/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0843\n","Epoch 61: loss did not improve from 0.08281\n","62/62 [==============================] - 11s 179ms/step - loss: 0.0843\n","Epoch 62/100\n","62/62 [==============================] - ETA: 0s - loss: 0.0861\n","Epoch 62: loss did not improve from 0.08281\n","62/62 [==============================] - 12s 181ms/step - loss: 0.0861\n","Epoch 63/100\n","62/62 [==============================] - ETA: 0s - loss: 0.1169\n","Epoch 63: loss did not improve from 0.08281\n","62/62 [==============================] - 12s 182ms/step - loss: 0.1169\n","Epoch 64/100\n","62/62 [==============================] - ETA: 0s - loss: 0.5887\n","Epoch 64: loss did not improve from 0.08281\n","62/62 [==============================] - 12s 182ms/step - loss: 0.5887\n","Epoch 65/100\n","62/62 [==============================] - ETA: 0s - loss: 1.1425\n","Epoch 65: loss did not improve from 0.08281\n","62/62 [==============================] - 12s 187ms/step - loss: 1.1425\n"]}]},{"cell_type":"markdown","source":["## Generador de texto basado en palabras"],"metadata":{"id":"t_JBRhLxgEwF"}},{"cell_type":"markdown","source":["Define una clase para generar texto palabra por palabra."],"metadata":{"id":"tBXm92lbgGgB"}},{"cell_type":"code","source":["class WordGenerator(tf.keras.Model):\n","    def __init__(self, model, words_from_ids, ids_from_words, temperature=1.0):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.model = model\n","        self.words_from_ids = words_from_ids\n","        self.ids_from_words = ids_from_words\n","\n","    def generate_words(self, seed_text, num_words=50, states=None):\n","      # Convertir las palabras de entrada en IDs\n","      input_ids = self.ids_from_words(tf.strings.split(seed_text))\n","      input_ids = tf.expand_dims(input_ids, axis=0)  # Agregar dimensión para el batch\n","\n","      result = [seed_text]  # Lista de palabras generadas, comenzando con el texto inicial\n","\n","      for _ in range(num_words):\n","          # Obtener las predicciones del modelo\n","          predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n","          # Ajustar las probabilidades según la temperatura\n","          predicted_logits = predicted_logits[:, -1, :] / self.temperature\n","          # Generar una palabra basada en las probabilidades ajustadas\n","          predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","          predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","          # Convertir el ID predicho en la palabra correspondiente\n","          predicted_word = self.words_from_ids(predicted_ids).numpy()\n","\n","          # Si `predicted_word` es un arreglo, convertir cada elemento a str\n","          if isinstance(predicted_word, np.ndarray):\n","              predicted_word = predicted_word[0].decode('utf-8')  # Decodificar el primer elemento\n","\n","          result.append(predicted_word)\n","\n","          # Actualizar el input para la próxima iteración\n","          input_ids = tf.expand_dims(predicted_ids, axis=0)\n","\n","      # Unir las palabras generadas en un texto\n","      return ' '.join(result)"],"metadata":{"id":"Q4Q_n8BSgHjK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generación de texto"],"metadata":{"id":"7a6a6ttAgJp3"}},{"cell_type":"markdown","source":["Usa el generador de texto para crear nuevas secuencias basadas en palabras."],"metadata":{"id":"l2pad-yIgLEM"}},{"cell_type":"code","source":["# Instanciar el generador de texto con el modelo entrenado\n","word_gen_model = WordGenerator(word_based_model, words_from_ids, ids_from_words, temperature=0.5)\n","\n","# Generar texto\n","seed_text = \"To be or not to be\"\n","generated_text = word_gen_model.generate_words(seed_text=seed_text, num_words=50)\n","print(f\"Texto generado con temperatura 0.5:\\n{generated_text}\")\n","\n","# Experimentar con otra temperatura\n","word_gen_model_high_temp = WordGenerator(word_based_model, words_from_ids, ids_from_words, temperature=1.5)\n","generated_text_high_temp = word_gen_model_high_temp.generate_words(seed_text=seed_text, num_words=50)\n","print(f\"Texto generado con temperatura 1.5:\\n{generated_text_high_temp}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfr6OJRTgLt9","executionInfo":{"status":"ok","timestamp":1732661373782,"user_tz":180,"elapsed":4047,"user":{"displayName":"Julian Britos","userId":"04222548301686831420"}},"outputId":"d540a360-7c81-4dad-ba6c-881adc5885f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto generado con temperatura 0.5:\n","To be or not to be a king, As poisonous than a poor traitor to instruct your sword, Which came becomes your sword, and gentle wind May instruct your shame, But mercy to be your day we do hold your daughter and your purpose to your shame, And then, and reconcile us your fortune side and\n","Texto generado con temperatura 1.5:\n","To be or not to be a king, That did upon me: if his words might fall you that my hand. Shepherd: Never? and wrathful no, you must not speak with us? I am your queen, with Licio. LUCIO: When you have been Me for, another's Above the best of war, ourselves to his purpose and\n"]}]},{"cell_type":"markdown","source":["Como ya habíamos concluido, es notable que la temperatura hace una modificación en la creatividad y coherencia en la generación de texto.\n","Siendo que al tener temperaturas bajas, obtenemos resultados más seguros, coherentes, estructuras que se va perdiendo al ir aumentando la temperatura."],"metadata":{"id":"1LaGBEtbvAqj"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["DHC5HT_ihaJH"]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}